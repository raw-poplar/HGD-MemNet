#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ€§èƒ½æµ‹è¯• - ç›´æ¥æµ‹è¯•æ ¸å¿ƒå‡½æ•°
"""

import time
import json
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
import config
from src.dataset import Vocabulary
from src.prepare_binary_data import process_dialogue_to_tensors

def test_core_performance():
    """æµ‹è¯•æ ¸å¿ƒå¤„ç†æ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•æ ¸å¿ƒå¤„ç†æ€§èƒ½...")
    
    # åˆ›å»ºè¯æ±‡è¡¨
    vocab = Vocabulary("test")
    vocab.addSentence("ä½ å¥½ ä¸–ç•Œ æµ‹è¯• æ•°æ®")
    vocab.addSentence("å¾ˆå¥½ å†è§ è°¢è°¢")
    
    # åˆ›å»ºæµ‹è¯•å¯¹è¯
    test_dialogues = []
    for i in range(1000):
        dialogue = [
            {"text": f"ä½ å¥½ä¸–ç•Œ {i}"},
            {"text": f"ä½ å¥½å— {i}"},
            {"text": f"æˆ‘å¾ˆå¥½ {i}"},
            {"text": f"å†è§ {i}"}
        ]
        test_dialogues.append(dialogue)
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_dialogues)} ä¸ªå¯¹è¯")
    print(f"ğŸ“š è¯æ±‡è¡¨å¤§å°: {vocab.num_words}")
    
    # æµ‹è¯•å¤„ç†é€Ÿåº¦
    start_time = time.time()
    
    processed_count = 0
    for dialogue in test_dialogues:
        result = process_dialogue_to_tensors(dialogue, vocab)
        if result:
            processed_count += 1
    
    end_time = time.time()
    duration = end_time - start_time
    speed = len(test_dialogues) / duration
    
    print(f"âœ… å¤„ç†ç»“æœ: {processed_count}/{len(test_dialogues)} ä¸ªå¯¹è¯")
    print(f"â±ï¸  å¤„ç†æ—¶é—´: {duration:.2f}s")
    print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {speed:.1f} it/s")
    
    return speed

def analyze_bottlenecks():
    """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
    print(f"\nğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æ:")
    
    vocab = Vocabulary("test")
    vocab.addSentence("æµ‹è¯• æ•°æ®")
    
    # æµ‹è¯•JSONè§£æ
    test_dialogue = [{"text": "ä½ å¥½ä¸–ç•Œ"}, {"text": "ä½ å¥½å—"}]
    test_json = json.dumps(test_dialogue, ensure_ascii=False)
    
    start_time = time.time()
    for _ in range(10000):
        json.loads(test_json)
    json_time = time.time() - start_time
    print(f"   ğŸ“„ JSONè§£æ: {json_time*100:.2f}ms/1000æ¬¡")
    
    # æµ‹è¯•å¼ é‡åˆ›å»º
    import torch
    start_time = time.time()
    for _ in range(10000):
        torch.tensor([1, 2, 3, 4, 5], dtype=torch.long)
    tensor_time = time.time() - start_time
    print(f"   ğŸ”¢ å¼ é‡åˆ›å»º: {tensor_time*100:.2f}ms/1000æ¬¡")
    
    # æµ‹è¯•è¯æ±‡è¡¨æŸ¥æ‰¾
    start_time = time.time()
    for _ in range(10000):
        vocab.word2index.get("æµ‹è¯•", config.UNK_token)
    lookup_time = time.time() - start_time
    print(f"   ğŸ“š è¯æ±‡æŸ¥æ‰¾: {lookup_time*100:.2f}ms/1000æ¬¡")

def estimate_multiprocessing_benefit():
    """ä¼°ç®—å¤šè¿›ç¨‹æ”¶ç›Š"""
    print(f"\nğŸ“Š å¤šè¿›ç¨‹æ”¶ç›Šä¼°ç®—:")
    
    # åŸºå‡†æ€§èƒ½
    base_speed = test_core_performance()
    
    print(f"\nğŸ’¡ ç†è®ºåˆ†æ:")
    print(f"   å•çº¿ç¨‹åŸºå‡†é€Ÿåº¦: {base_speed:.1f} it/s")
    
    # ä¼°ç®—ä¸åŒworkeræ•°çš„ç†è®ºé€Ÿåº¦
    import multiprocessing
    cpu_count = multiprocessing.cpu_count()
    print(f"   å¯ç”¨CPUæ ¸å¿ƒ: {cpu_count}")
    
    # è€ƒè™‘å¼€é”€çš„ç†è®ºé€Ÿåº¦
    overheads = {
        1: 1.0,    # æ— å¤šè¿›ç¨‹å¼€é”€
        2: 0.85,   # 15% å¼€é”€
        4: 0.75,   # 25% å¼€é”€  
        8: 0.65,   # 35% å¼€é”€
    }
    
    print(f"\n   ç†è®ºå¤šè¿›ç¨‹é€Ÿåº¦ (è€ƒè™‘å¼€é”€):")
    for workers in [1, 2, 4, 8]:
        if workers <= cpu_count:
            theoretical_speed = base_speed * workers * overheads.get(workers, 0.5)
            improvement = theoretical_speed / base_speed
            print(f"     {workers} workers: {theoretical_speed:.1f} it/s ({improvement:.1f}x)")

def check_io_bottleneck():
    """æ£€æŸ¥I/Oç“¶é¢ˆ"""
    print(f"\nğŸ’¾ I/Oç“¶é¢ˆæ£€æŸ¥:")
    
    import torch
    import tempfile
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = []
    for _ in range(100):  # å¿½ç•¥æœªä½¿ç”¨çš„å¾ªç¯å˜é‡
        x_ref = torch.randint(0, 1000, (10,), dtype=torch.long)
        steps = [(torch.randint(0, 1000, (5,), dtype=torch.long), 
                 torch.randint(0, 1000, (8,), dtype=torch.long),
                 torch.tensor([1.0], dtype=torch.float)) for _ in range(10)]
        test_data.append((x_ref, steps))
    
    # æµ‹è¯•ä¿å­˜é€Ÿåº¦
    with tempfile.NamedTemporaryFile(suffix='.pt', delete=False) as f:
        temp_file = f.name
    
    start_time = time.time()
    torch.save(test_data, temp_file)
    save_time = time.time() - start_time
    
    # æµ‹è¯•åŠ è½½é€Ÿåº¦
    start_time = time.time()
    _ = torch.load(temp_file, weights_only=True)  # å¿½ç•¥åŠ è½½çš„æ•°æ®
    load_time = time.time() - start_time
    
    # æ¸…ç†
    os.unlink(temp_file)
    
    file_size = len(str(test_data)) / 1024 / 1024  # ä¼°ç®—å¤§å°
    
    print(f"   ğŸ’¾ ä¿å­˜é€Ÿåº¦: {save_time*1000:.2f}ms ({file_size:.2f}MB)")
    print(f"   ğŸ“‚ åŠ è½½é€Ÿåº¦: {load_time*1000:.2f}ms")
    
    if save_time > 0.1:  # å¦‚æœä¿å­˜æ—¶é—´è¶…è¿‡100ms
        print(f"   âš ï¸  I/Oå¯èƒ½æˆä¸ºç“¶é¢ˆ")
    else:
        print(f"   âœ… I/Oé€Ÿåº¦è‰¯å¥½")

def main():
    print("ğŸš€ å¿«é€Ÿæ€§èƒ½æµ‹è¯•...")
    
    try:
        # æ ¸å¿ƒæ€§èƒ½æµ‹è¯•
        base_speed = test_core_performance()
        
        # ç“¶é¢ˆåˆ†æ
        analyze_bottlenecks()
        
        # å¤šè¿›ç¨‹æ”¶ç›Šä¼°ç®—
        estimate_multiprocessing_benefit()
        
        # I/Oç“¶é¢ˆæ£€æŸ¥
        check_io_bottleneck()
        
        print(f"\nğŸ¯ ç»“è®ºå’Œå»ºè®®:")
        
        if base_speed > 1000:
            print(f"âœ… æ ¸å¿ƒå¤„ç†é€Ÿåº¦è‰¯å¥½ ({base_speed:.1f} it/s)")
            print(f"ğŸ’¡ å¤šè¿›ç¨‹å¯èƒ½æœ‰æ•ˆï¼Œå»ºè®®ä½¿ç”¨2-4ä¸ªworker")
        elif base_speed > 100:
            print(f"âš ï¸  æ ¸å¿ƒå¤„ç†é€Ÿåº¦ä¸­ç­‰ ({base_speed:.1f} it/s)")
            print(f"ğŸ’¡ å¤šè¿›ç¨‹æ”¶ç›Šæœ‰é™ï¼Œå»ºè®®ä½¿ç”¨1-2ä¸ªworker")
        else:
            print(f"âŒ æ ¸å¿ƒå¤„ç†é€Ÿåº¦è¾ƒæ…¢ ({base_speed:.1f} it/s)")
            print(f"ğŸ’¡ å»ºè®®ä¼˜åŒ–æ ¸å¿ƒç®—æ³•ï¼Œå¤šè¿›ç¨‹æ”¶ç›Šä¸å¤§")
        
        print(f"\nğŸ“‹ ä¼˜åŒ–å»ºè®®:")
        print(f"1. å¦‚æœé€Ÿåº¦ > 100 it/sï¼Œå¯ä»¥å°è¯•å¤šè¿›ç¨‹")
        print(f"2. å¦‚æœé€Ÿåº¦ < 100 it/sï¼Œä¼˜å…ˆä¼˜åŒ–å•çº¿ç¨‹æ€§èƒ½")
        print(f"3. ç›‘æ§å†…å­˜ä½¿ç”¨ï¼Œé¿å…å†…å­˜ä¸è¶³")
        print(f"4. è€ƒè™‘ä½¿ç”¨SSDæé«˜I/Oæ€§èƒ½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
