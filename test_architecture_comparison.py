# -*- coding: utf-8 -*-
"""
HGD-MemNetæ¶æ„å¯¹æ¯”æµ‹è¯•è„šæœ¬
æµ‹è¯•æœ‰æ³¨æ„åŠ›æœºåˆ¶ vs æ— æ³¨æ„åŠ›æœºåˆ¶çš„æ€§èƒ½å·®å¼‚
"""

import torch
import torch.nn as nn
import config
from src.model import HGD_MemNet
import time
import numpy as np

def test_architecture_performance():
    """æµ‹è¯•ä¸¤ç§æ¶æ„çš„æ€§èƒ½å¯¹æ¯”"""
    
    # è®¾ç½®æµ‹è¯•å‚æ•°
    batch_size = 4
    seq_len = 10
    vocab_size = 1000
    
    print("=" * 60)
    print("HGD-MemNet æ¶æ„å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    x_t = torch.randint(0, vocab_size, (batch_size, seq_len))
    x_ref = torch.randint(0, vocab_size, (batch_size, seq_len * 2))
    h_prev = torch.zeros(batch_size, config.DYNAMIC_GROUP_HIDDEN_DIM)
    
    print(f"æµ‹è¯•æ•°æ®: batch_size={batch_size}, seq_len={seq_len}")
    print(f"æ¨¡å‹å‚æ•°: embed_dim={config.EMBEDDING_DIM}, hidden_dim={config.DYNAMIC_GROUP_HIDDEN_DIM}")
    print()
    
    # æµ‹è¯•1: æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„HGD-MemNet
    print("ğŸ” æµ‹è¯•1: HGD-MemNet + æ³¨æ„åŠ›æœºåˆ¶")
    model_with_attention = HGD_MemNet(
        vocab_size=vocab_size,
        embed_dim=config.EMBEDDING_DIM,
        dynamic_hidden_dim=config.DYNAMIC_GROUP_HIDDEN_DIM,
        static_hidden_dim=config.STATIC_HEAD_HIDDEN_DIM,
        use_attention=True
    )
    
    # æ€§èƒ½æµ‹è¯•
    start_time = time.time()
    with torch.no_grad():
        for _ in range(100):
            h_next, gate_pred, output_logits = model_with_attention(x_t, x_ref, h_prev)
    attention_time = time.time() - start_time
    
    # å‚æ•°ç»Ÿè®¡
    attention_params = sum(p.numel() for p in model_with_attention.parameters())
    
    print(f"  âœ“ å‰å‘ä¼ æ’­100æ¬¡è€—æ—¶: {attention_time:.4f}ç§’")
    print(f"  âœ“ æ¨¡å‹å‚æ•°é‡: {attention_params:,}")
    print(f"  âœ“ è¾“å‡ºå½¢çŠ¶: h_next={h_next.shape}, gate={gate_pred.shape}, logits={output_logits.shape}")
    print()
    
    # æµ‹è¯•2: çº¯HGD-MemNetï¼ˆæ— æ³¨æ„åŠ›ï¼‰
    print("ğŸ§  æµ‹è¯•2: çº¯HGD-MemNetæ¶æ„")
    model_without_attention = HGD_MemNet(
        vocab_size=vocab_size,
        embed_dim=config.EMBEDDING_DIM,
        dynamic_hidden_dim=config.DYNAMIC_GROUP_HIDDEN_DIM,
        static_hidden_dim=config.STATIC_HEAD_HIDDEN_DIM,
        use_attention=False
    )
    
    # æ€§èƒ½æµ‹è¯•
    start_time = time.time()
    with torch.no_grad():
        for _ in range(100):
            h_next, gate_pred, output_logits = model_without_attention(x_t, x_ref, h_prev)
    no_attention_time = time.time() - start_time
    
    # å‚æ•°ç»Ÿè®¡
    no_attention_params = sum(p.numel() for p in model_without_attention.parameters())
    
    print(f"  âœ“ å‰å‘ä¼ æ’­100æ¬¡è€—æ—¶: {no_attention_time:.4f}ç§’")
    print(f"  âœ“ æ¨¡å‹å‚æ•°é‡: {no_attention_params:,}")
    print(f"  âœ“ è¾“å‡ºå½¢çŠ¶: h_next={h_next.shape}, gate={gate_pred.shape}, logits={output_logits.shape}")
    print()
    
    # å¯¹æ¯”åˆ†æ
    print("ğŸ“Š å¯¹æ¯”åˆ†æ")
    print("-" * 40)
    speed_improvement = (attention_time - no_attention_time) / attention_time * 100
    param_reduction = (attention_params - no_attention_params) / attention_params * 100
    
    print(f"é€Ÿåº¦æå‡: {speed_improvement:+.2f}% ({'æ›´å¿«' if speed_improvement > 0 else 'æ›´æ…¢'})")
    print(f"å‚æ•°å‡å°‘: {param_reduction:+.2f}% ({abs(param_reduction):.0f}ä¸ªå‚æ•°)")
    print(f"å†…å­˜æ•ˆç‡: {'çº¯HGD-MemNetæ›´ä¼˜' if param_reduction > 0 else 'æ··åˆæ¶æ„æ›´ä¼˜'}")
    print()
    
    return {
        'with_attention': {
            'time': attention_time,
            'params': attention_params,
            'model': model_with_attention
        },
        'without_attention': {
            'time': no_attention_time,
            'params': no_attention_params,
            'model': model_without_attention
        }
    }

def test_thinking_mechanism():
    """æµ‹è¯•æ€è€ƒæœºåˆ¶çš„å·®å¼‚"""
    print("ğŸ§  æ€è€ƒæœºåˆ¶å¯¹æ¯”æµ‹è¯•")
    print("-" * 40)
    
    batch_size = 2
    seq_len = 5
    vocab_size = 100
    thinking_steps = 5
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    x_ref = torch.randint(0, vocab_size, (batch_size, seq_len))
    h_init = torch.zeros(batch_size, config.DYNAMIC_GROUP_HIDDEN_DIM)
    
    # æµ‹è¯•ä¸¤ç§æ¶æ„çš„æ€è€ƒæ¼”åŒ–
    models = {
        'æœ‰æ³¨æ„åŠ›': HGD_MemNet(vocab_size, config.EMBEDDING_DIM, 
                              config.DYNAMIC_GROUP_HIDDEN_DIM, 
                              config.STATIC_HEAD_HIDDEN_DIM, True),
        'æ— æ³¨æ„åŠ›': HGD_MemNet(vocab_size, config.EMBEDDING_DIM, 
                              config.DYNAMIC_GROUP_HIDDEN_DIM, 
                              config.STATIC_HEAD_HIDDEN_DIM, False)
    }
    
    for name, model in models.items():
        print(f"\n{name}æ¶æ„çš„æ€è€ƒæ¼”åŒ–:")
        h_prev = h_init.clone()
        
        for step in range(thinking_steps):
            with torch.no_grad():
                h_next, gate_pred, _ = model(None, x_ref, h_prev)  # x_t=Noneè¡¨ç¤ºçº¯æ€è€ƒ
                
                # è®¡ç®—æ€è€ƒå˜åŒ–ç¨‹åº¦
                change_magnitude = torch.norm(h_next - h_prev).item()
                avg_gate = torch.mean(gate_pred).item()
                
                print(f"  æ­¥éª¤{step+1}: å˜åŒ–å¹…åº¦={change_magnitude:.4f}, å¹³å‡é—¨æ§={avg_gate:.4f}")
                h_prev = h_next
    
    print()

if __name__ == "__main__":
    print("å¼€å§‹HGD-MemNetæ¶æ„å¯¹æ¯”æµ‹è¯•...\n")
    
    # åŸºç¡€æ€§èƒ½å¯¹æ¯”
    results = test_architecture_performance()
    
    # æ€è€ƒæœºåˆ¶å¯¹æ¯”
    test_thinking_mechanism()
    
    print("ğŸ¯ å»ºè®®:")
    print("1. å¦‚æœè¿½æ±‚çº¯ç²¹çš„HGD-MemNetåˆ›æ–°æ€§ï¼Œä½¿ç”¨æ— æ³¨æ„åŠ›ç‰ˆæœ¬")
    print("2. å¦‚æœéœ€è¦ä¸Transformerå¯¹æ¯”ï¼Œä½¿ç”¨æœ‰æ³¨æ„åŠ›ç‰ˆæœ¬")
    print("3. å¯ä»¥å…ˆç”¨æ— æ³¨æ„åŠ›ç‰ˆæœ¬éªŒè¯æ ¸å¿ƒæ€è€ƒæœºåˆ¶ï¼Œå†åŠ å…¥æ³¨æ„åŠ›ä¼˜åŒ–")
    print("4. å»ºè®®åœ¨æ‚¨çš„é¥¥é¥¿å¼è®­ç»ƒå®éªŒä¸­åŒæ—¶æµ‹è¯•ä¸¤ç§æ¶æ„")
