1. 权重剪枝，现在的模型架构是动态神经元之间两两相连，假如令模型的权重在训练过程中如果小于一定值（或者不满足一定条件），就丢弃这个权重，即这两个神经元之间没有直接联系，不能直接进行数据交换了；
2. 神经元剪枝，为所有的神经元增加一个能够令这个神经元对所有与这个神经元相连接的其他神经元进行评价的方法，也就是某个神经元能够从所有与它相连接的其他神经元那里获取自己的评价分数，而当这个评价分数低于一定值我们就重置这个神经元；
2.1. 对于第2点我们可以不单单使用一个神经元，我们可以使用一组数量的神经元，统计出这一组数量的神经元的输入输出，然后按照第2点来按组评价，如果评价分数低则重置这一组神经元的内部权重；
3. 当动态神经组中的神经元换成其他架构的神经网络后的训练方法改进，我们先拿到一个训练好的hgd-memnet，取出其中的一个或数个神经元，然后取一个其他架构的神经网络（这里我们先使用transformer架构网络作说明），我们使用hgd-memnet取出的神经元对transformer网络做强化学习，训练完后使用transformer网络替换掉原来的hgd-memnet的神经元，成为transformer神经元，然后接着学习
3.1. 在3的基础上，我们可以尝试将transformer神经元做的比较大并且多引入几个transformer神经元，我们将这些比较大的神经元合起来成为动态中枢神经组，然后引入动态模式和缓态模式，动态模式就是动态神经组全部神经元都处在运行状态，缓态模式则是只有动态中枢神经组处于运行状态。