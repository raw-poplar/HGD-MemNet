#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•è„šæœ¬
æµ‹è¯•HGD-MemNeté¡¹ç›®çš„å„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import torch
import json
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(__file__))

def test_imports():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å¯¼å…¥"""
    print("=== æµ‹è¯•æ¨¡å—å¯¼å…¥ ===")
    try:
        import config
        print("âœ“ config å¯¼å…¥æˆåŠŸ")
        
        from src.model import HGD_MemNet, ReservoirRNNCell, DynamicGroup, StaticHead
        print("âœ“ model ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        
        from src.dataset import Vocabulary, BinaryDialogueDataset, binary_collate_fn
        print("âœ“ dataset ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        
        from src.utils import load_model_from_checkpoint, compute_loss
        print("âœ“ utils ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºå’ŒåŸºæœ¬å‰å‘ä¼ æ’­"""
    print("\n=== æµ‹è¯•æ¨¡å‹åˆ›å»º ===")
    try:
        import config
        from src.model import HGD_MemNet

        model = HGD_MemNet(
            vocab_size=1000,
            embed_dim=64,
            dynamic_hidden_dim=128,
            static_hidden_dim=64
        )
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        x_t = torch.randint(0, 1000, (batch_size, 5))
        x_ref = torch.randint(0, 1000, (batch_size, 10))
        h_prev = torch.zeros(batch_size, 128)
        
        with torch.no_grad():
            h_next, gate_pred, output_logits = model(x_t, x_ref, h_prev)
        
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ: h_next={h_next.shape}, gate_pred={gate_pred.shape}, output_logits={output_logits.shape}")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_vocabulary():
    """æµ‹è¯•è¯æ±‡è¡¨åŠŸèƒ½"""
    print("\n=== æµ‹è¯•è¯æ±‡è¡¨ ===")
    try:
        from src.dataset import Vocabulary
        import config
        
        vocab = Vocabulary("test")
        vocab.addSentence("hello world test")
        vocab.addSentence("this is a test")
        
        print(f"âœ“ è¯æ±‡è¡¨åˆ›å»ºæˆåŠŸï¼Œè¯æ±‡æ•°é‡: {vocab.num_words}")
        
        # æµ‹è¯•trimåŠŸèƒ½
        vocab.trim(min_count=1)
        print(f"âœ“ è¯æ±‡è¡¨ä¿®å‰ªæˆåŠŸï¼Œä¿®å‰ªåè¯æ±‡æ•°é‡: {vocab.num_words}")
        
        return True
        
    except Exception as e:
        print(f"âœ— è¯æ±‡è¡¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_loss_computation():
    """æµ‹è¯•æŸå¤±è®¡ç®—"""
    print("\n=== æµ‹è¯•æŸå¤±è®¡ç®— ===")
    try:
        from src.utils import compute_loss
        import config

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        vocab_size = 100  # ä½¿ç”¨å›ºå®šçš„è¯æ±‡è¡¨å¤§å°è¿›è¡Œæµ‹è¯•
        batch_size = 4
        seq_len = 5
        gate_pred = torch.sigmoid(torch.randn(batch_size, 1))
        gate_target = torch.randint(0, 2, (batch_size,)).float()
        output_logits = torch.randn(batch_size, vocab_size)
        target_padded = torch.randint(0, vocab_size, (batch_size, 1))  # ä¿®æ­£ï¼šç¡®ä¿ç»´åº¦åŒ¹é…

        # ä¸´æ—¶è®¾ç½®config.VOCAB_SIZE
        original_vocab_size = getattr(config, 'VOCAB_SIZE', None)
        config.VOCAB_SIZE = vocab_size
        
        loss = compute_loss(gate_pred, gate_target, output_logits, target_padded)
        print(f"âœ“ æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.4f}")

        # æµ‹è¯•æ— targetçš„æƒ…å†µ
        loss_no_target = compute_loss(gate_pred, gate_target, output_logits, None)
        print(f"âœ“ æ— targetæŸå¤±è®¡ç®—æˆåŠŸ: {loss_no_target.item():.4f}")

        # æ¢å¤åŸå§‹vocab_size
        if original_vocab_size is not None:
            config.VOCAB_SIZE = original_vocab_size

        return True
        
    except Exception as e:
        print(f"âœ— æŸå¤±è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_reservoir_rnn_cell():
    """æµ‹è¯•ReservoirRNNCellçš„ç‰¹æ®ŠåŠŸèƒ½"""
    print("\n=== æµ‹è¯•ReservoirRNNCell ===")
    try:
        from src.model import ReservoirRNNCell
        import config
        
        cell = ReservoirRNNCell(
            input_size=64,
            hidden_size=128,
            initial_temperature=1.0,
            use_hard_sampling=False
        )
        
        batch_size = 3
        x_t = torch.randn(batch_size, 64)
        h_prev = torch.randn(batch_size, 128)
        
        # æµ‹è¯•ä¸åŒæ¸©åº¦
        h_next_1 = cell(x_t, h_prev, temperature=1.0)
        h_next_2 = cell(x_t, h_prev, temperature=0.1)
        
        print(f"âœ“ ReservoirRNNCellæµ‹è¯•æˆåŠŸ: è¾“å‡ºå½¢çŠ¶ {h_next_1.shape}")
        print(f"âœ“ æ¸©åº¦æ§åˆ¶æµ‹è¯•æˆåŠŸ: é«˜æ¸©å’Œä½æ¸©è¾“å‡ºä¸åŒ")
        
        # æµ‹è¯•è™šæ‹Ÿæƒé‡æ›´æ–°
        initial_virtual_weights = cell.W_hh_virtual.clone()
        _ = cell(x_t, h_prev)  # è§¦å‘èµ«å¸ƒæ›´æ–°
        updated_virtual_weights = cell.W_hh_virtual.clone()
        
        weights_changed = not torch.equal(initial_virtual_weights, updated_virtual_weights)
        print(f"âœ“ è™šæ‹Ÿæƒé‡æ›´æ–°æµ‹è¯•: {'æˆåŠŸ' if weights_changed else 'å¤±è´¥'}")
        
        return True
        
    except Exception as e:
        print(f"âœ— ReservoirRNNCellæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_config_consistency():
    """æµ‹è¯•é…ç½®æ–‡ä»¶çš„ä¸€è‡´æ€§"""
    print("\n=== æµ‹è¯•é…ç½®ä¸€è‡´æ€§ ===")
    try:
        import config
        
        # æ£€æŸ¥å…³é”®é…ç½®æ˜¯å¦å­˜åœ¨
        required_configs = [
            'VOCAB_SIZE', 'EMBEDDING_DIM', 'DYNAMIC_GROUP_HIDDEN_DIM',
            'STATIC_HEAD_HIDDEN_DIM', 'BATCH_SIZE', 'LEARNING_RATE',
            'THINKING_STEPS', 'FIXED_SAMPLING_RATIO', 'RANDOM_SAMPLING_RATIO'
        ]
        
        missing_configs = []
        for cfg in required_configs:
            if not hasattr(config, cfg):
                missing_configs.append(cfg)
        
        if missing_configs:
            print(f"âœ— ç¼ºå°‘é…ç½®é¡¹: {missing_configs}")
            return False
        
        # æ£€æŸ¥é…ç½®å€¼çš„åˆç†æ€§
        if config.FIXED_SAMPLING_RATIO + config.RANDOM_SAMPLING_RATIO > 1.0:
            print("âœ— é‡‡æ ·æ¯”ä¾‹ä¹‹å’Œè¶…è¿‡1.0")
            return False
        
        print("âœ“ é…ç½®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹HGD-MemNetç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•...\n")
    
    tests = [
        test_imports,
        test_config_consistency,
        test_vocabulary,
        test_model_creation,
        test_loss_computation,
        test_reservoir_rnn_cell,
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¼‚å¸¸: {e}")
    
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"é€šè¿‡: {passed}/{total}")
    print(f"æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
