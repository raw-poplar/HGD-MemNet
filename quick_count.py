#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿç»Ÿè®¡å¤„ç†è¿›åº¦
"""

import os
import glob

def quick_count():
    """å¿«é€Ÿç»Ÿè®¡"""
    print("ğŸ“Š å¿«é€Ÿç»Ÿè®¡å¤„ç†è¿›åº¦...")
    
    # ç›´æ¥æœç´¢chunkæ–‡ä»¶
    chunk_pattern = "F:/modelTrain/data/lccc_processed/train/chunk_*.pt"
    chunk_files = glob.glob(chunk_pattern)
    
    if not chunk_files:
        print("âŒ æœªæ‰¾åˆ°chunkæ–‡ä»¶")
        return
    
    print(f"ğŸ“¦ æ‰¾åˆ° {len(chunk_files)} ä¸ªchunkæ–‡ä»¶")
    
    # è·å–chunkç¼–å·
    chunk_numbers = []
    for file_path in chunk_files:
        filename = os.path.basename(file_path)
        try:
            num = int(filename.split('_')[1].split('.')[0])
            chunk_numbers.append(num)
        except:
            pass
    
    if chunk_numbers:
        chunk_numbers.sort()
        print(f"ğŸ”¢ ç¼–å·èŒƒå›´: {min(chunk_numbers)} - {max(chunk_numbers)}")
        print(f"ğŸ“ˆ æœ€å¤§chunkç¼–å·: {max(chunk_numbers)}")
        print(f"ğŸ“Š æ€»chunkæ•°: {len(chunk_numbers)}")
        
        # æ£€æŸ¥è¿ç»­æ€§
        expected = list(range(min(chunk_numbers), max(chunk_numbers) + 1))
        missing = set(expected) - set(chunk_numbers)
        if missing:
            print(f"âš ï¸  ç¼ºå¤±ç¼–å·: {sorted(missing)}")
        else:
            print(f"âœ… ç¼–å·è¿ç»­")
        
        # ä¼°ç®—å¤„ç†è¿›åº¦
        # å‡è®¾æ¯ä¸ªchunkåŒ…å«çº¦10000ä¸ªå¯¹è¯
        estimated_dialogues = len(chunk_numbers) * 10000
        print(f"\nğŸ“Š ä¼°ç®—ç»Ÿè®¡:")
        print(f"   ğŸ—£ï¸  ä¼°ç®—å·²å¤„ç†å¯¹è¯æ•°: {estimated_dialogues:,}")
        
        # åŸºäºchunkæ•°é‡ä¼°ç®—å¤„ç†çš„è¡Œæ•°
        # train.jsonl å¤§çº¦æœ‰ 15,220,604 è¡Œï¼ˆä»ä¹‹å‰çš„ä¼°ç®—ï¼‰
        total_estimated_lines = 15220604
        
        # å‡è®¾æ¯ä¸ªchunkå¯¹åº”çº¦ 20000 è¡ŒåŸå§‹æ•°æ®
        estimated_processed_lines = len(chunk_numbers) * 20000
        
        print(f"   ğŸ“„ ä¼°ç®—å·²å¤„ç†è¡Œæ•°: {estimated_processed_lines:,}")
        
        if total_estimated_lines > 0:
            progress = min(estimated_processed_lines / total_estimated_lines * 100, 100)
            print(f"   ğŸ“ˆ ä¼°ç®—å¤„ç†è¿›åº¦: {progress:.1f}%")
            
            remaining_lines = max(0, total_estimated_lines - estimated_processed_lines)
            print(f"   â³ ä¼°ç®—å‰©ä½™è¡Œæ•°: {remaining_lines:,}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    print(f"\nğŸ’¾ æ–‡ä»¶å¤§å°ç»Ÿè®¡:")
    total_size = 0
    for file_path in chunk_files[:5]:  # æ£€æŸ¥å‰5ä¸ªæ–‡ä»¶
        try:
            size = os.path.getsize(file_path)
            total_size += size
            filename = os.path.basename(file_path)
            print(f"   {filename}: {size / (1024*1024):.2f} MB")
        except:
            pass
    
    if len(chunk_files) > 0:
        avg_size = total_size / min(len(chunk_files), 5)
        estimated_total_size = avg_size * len(chunk_files)
        print(f"   ğŸ“Š ä¼°ç®—æ€»å¤§å°: {estimated_total_size / (1024*1024*1024):.2f} GB")

if __name__ == "__main__":
    quick_count()
